diff --git a/tracking/data_loader.py b/tracking/data_loader.py
index 1a99c3c..7ceca07 100644
--- a/tracking/data_loader.py
+++ b/tracking/data_loader.py
@@ -7,6 +7,7 @@ import random
 import numpy as np
 from torchvision import datasets, transforms, utils
 
+
 class TrackerDataLoader(object):
 
     def get_instance_image(self, img, bbox, size_z, size_x, context_amount, img_mean=None):
diff --git a/tracking/run_tracking.py b/tracking/run_tracking.py
index 68b9ed1..f154b31 100644
--- a/tracking/run_tracking.py
+++ b/tracking/run_tracking.py
@@ -4,19 +4,21 @@ from siamRPNBIG import TrackerSiamRPNBIG
 import argparse
 import os
 import json
+from train.experimentrgbt import ExperimentRGBT
+
 
-parser = argparse.ArgumentParser(description='PyTorch SiameseRPN Tracking')
 
-parser.add_argument('--tracker_path', default='/home/arbi/desktop/data', metavar='DIR',help='path to dataset')
+parser = argparse.ArgumentParser(description='PyTorch SiameseRPN Tracking')
+parser.add_argument('--tracker_path', default='/home/zuern/datasets/tracking/GOT10k', metavar='DIR',help='path to dataset')
 parser.add_argument('--experiment_name', default='default', metavar='DIR',help='path to weight')
-parser.add_argument('--net_path', default='../train/experiments/default/model/model_e17.pth', metavar='DIR',help='path to weight')
-# ../train/experiments/default/model/model_e1.pth # ../model.pth #../siamrpn_7.pth
-# /Users/arbi/Desktop # /home/arbi/desktop/GOT-10k
-# /media/arbi/9132EE0B9756C987/dataset/GOT-10k/full_data
-parser.add_argument('--visualize', default=True, help='visualize')
+parser.add_argument('--net_path', default='../train/experiments/SiamRPN/model/model_e1.pth', metavar='DIR',help='path to weight')
+
+parser.add_argument('--visualize', default=False, help='visualize')
 
 args = parser.parse_args()
 
+
+
 if __name__ == '__main__':
 
     """Load the parameters from json file"""
@@ -26,8 +28,13 @@ if __name__ == '__main__':
         params = json.load(data_file)
 
     '''setup tracker'''
+
+
+    # tracker = TrackerSiamRPNBIG(params, args.net_path)
     tracker = TrackerSiamRPNBIG(params, args.net_path)
 
+
+
     '''setup experiments'''
     # 7 datasets with different versions
     '''
@@ -54,11 +61,19 @@ if __name__ == '__main__':
                     report_dir='experiments/{}/reports'.format(args.experiment_name))
 
     '''
-    experiments = ExperimentOTB('/home/arbi/desktop/data', version=2015,
-                    result_dir='experiments/{}/OTB2015resultsGOT-10k_42'.format(args.experiment_name),
-                    report_dir='experiments/{}/OTB2015reportsGOT-10k_42'.format(args.experiment_name))
+    # experiments = ExperimentOTB('/home/arbi/desktop/data', version=2015,
+    #                 result_dir='experiments/{}/OTB2015resultsGOT-10k_42'.format(args.experiment_name),
+    #                 report_dir='experiments/{}/OTB2015reportsGOT-10k_42'.format(args.experiment_name))
+
+    experiments = ExperimentGOT10k(args.tracker_path, subset='val',
+                    result_dir='experiments/{}/results'.format(args.experiment_name),
+                    report_dir='experiments/{}/reports'.format(args.experiment_name))
+
+    experiments = ExperimentRGBT('/home/zuern/datasets/thermal_tracking/RGB-T234/',
+                       experiment_name='RGBT-Train',
+                       subset='val')
 
 
     '''run experiments'''
     experiments.run(tracker, visualize = args.visualize)
-    experiments.report([tracker.name])
+    experiments.report([tracker.name], return_report=False)
diff --git a/train/config.py b/train/config.py
index 76c65f1..b0195ef 100644
--- a/train/config.py
+++ b/train/config.py
@@ -37,7 +37,8 @@ class Config(object):
     out_feature = 19
     max_inter   = 80
     fix_former_3_layers = True
-    pretrained_model =  '/home/arbi/Загрузки/alexnet.pth' # '/home/arbi/desktop/alexnet.pth' # # '/Users/arbi/Desktop/alexnet.pth'
+    # pretrained_model =  '/home/arbi/Загрузки/alexnet.pth' # '/home/arbi/desktop/alexnet.pth' # # '/Users/arbi/Desktop/alexnet.pth'
+    pretrained_model =  None
 
     total_stride = 8
     anchor_total_stride = total_stride
diff --git a/train/experiments/default/parameters.json b/train/experiments/default/parameters.json
deleted file mode 100644
index 2a0a6ff..0000000
--- a/train/experiments/default/parameters.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "template_img_size": 127,
-    "detection_img_size": 271,
-    "stride": 8,
-    "lr": 1e-5,
-    "epoches": 200,
-    "weight_decay": 0.0005,
-    "momentum": 0.9,
-    "context": 0.5,
-    "ratios": [0.33, 0.5, 1, 2, 3],
-    "scales": [8],
-    "penalty_k": 0.055,
-    "window_influence": 0.42
-}
diff --git a/train/net.py b/train/net.py
index 611ae89..2a35d03 100644
--- a/train/net.py
+++ b/train/net.py
@@ -11,7 +11,12 @@ import matplotlib.pyplot as plt
 import torch.nn.functional as F
 from config import config
 from got10k.trackers import Tracker
+
+
 from network import SiameseAlexNet
+from network_siamfc import Net, SiamFC, AlexNetV3
+
+
 from loss import rpn_smoothL1, rpn_cross_entropy_balance
 
 class TrackerSiamRPN(Tracker):
@@ -26,7 +31,6 @@ class TrackerSiamRPN(Tracker):
 
         '''setup model'''
         self.net = SiameseAlexNet()
-        #self.net.init_weights()
 
         if net_path is not None:
             self.net.load_state_dict(torch.load(
@@ -76,30 +80,6 @@ class TrackerSiamRPN(Tracker):
 
         loss = cls_loss + config.lamb * reg_loss
 
-        '''anchors_show = anchors
-        exem_img = template[0].cpu().numpy().transpose(1, 2, 0)  # (127, 127, 3)
-        #cv2.imwrite('exem_img.png', exem_img)
-
-        inst_img = detection[0].cpu().numpy().transpose(1, 2, 0) # (255, 255, 3)
-        #cv2.imwrite('inst_img.png', inst_img)
-
-
-
-        topk = 1
-        cls_pred = F.softmax(pred_conf, dim=2)[0, :, 1]
-
-        topk_box = util.get_topk_box(cls_pred, pred_offset[0], anchors_show, topk=topk)
-        img_box = util.add_box_img(inst_img, topk_box, color=(0, 0, 255))
-
-        cv2.imwrite('pred_inst.png', img_box)
-
-        cls_pred = conf_target[0]
-        gt_box = util.get_topk_box(cls_pred, regression_target[0], anchors_show)
-        #print('gt_box', gt_box)
-        img_box = util.add_box_img(img_box, gt_box, color=(255, 0, 0), x = 1, y = 1)
-        #print('gt_box', gt_box)
-        cv2.imwrite('pred_inst_gt.png', img_box)'''
-
         if train:
             self.optimizer.zero_grad()
             loss.backward()
@@ -118,61 +98,88 @@ class TrackerSiamRPN(Tracker):
         net_path = os.path.join(model_save_dir_pth, 'model_e%d.pth' % (epoch + 1))
         torch.save(model.net.state_dict(), net_path)
 
-'''class SiamRPN(nn.Module):
-
-    def __init__(self, anchor_num = 5):
-        super(SiamRPN, self).__init__()
-
-        self.anchor_num = anchor_num
-        self.feature = nn.Sequential(
-            # conv1
-            nn.Conv2d(3, 64, kernel_size = 11, stride = 2),
-            nn.BatchNorm2d(64),
-            nn.ReLU(inplace = True),
-            nn.MaxPool2d(kernel_size = 3, stride = 2),
-            # conv2
-            nn.Conv2d(64, 192, kernel_size = 5),
-            nn.BatchNorm2d(192),
-            nn.ReLU(inplace=True),
-            nn.MaxPool2d(kernel_size = 3, stride = 2),
-            # conv3
-            nn.Conv2d(192, 384, kernel_size = 3),
-            nn.BatchNorm2d(384),
-            nn.ReLU(inplace = True),
-            # conv4
-            nn.Conv2d(384, 256, kernel_size = 3),
-            nn.BatchNorm2d(256),
-            nn.ReLU(inplace = True),
-            # conv5
-            nn.Conv2d(256, 256, kernel_size = 3),
-            nn.BatchNorm2d(256))
-
-        self.conv_reg_z = nn.Conv2d(256, 256 * 4 * self.anchor_num, 3, 1)
-        self.conv_reg_x = nn.Conv2d(256, 256, 3)
-        self.conv_cls_z = nn.Conv2d(256, 256 * 2 * anchor_num, 3, 1)
-        self.conv_cls_x = nn.Conv2d(256, 256, 3)
-        self.adjust_reg = nn.Conv2d(4 * anchor_num, 4 * anchor_num*1, 1)
-
-    def forward(self, z, x):
-        return self.inference(x, *self.learn(z))
-
-    def learn(self, z):
-        z = self.feature(z)
-        kernel_reg = self.conv_reg_z(z)
-        kernel_cls = self.conv_cls_z(z)
-
-        k = kernel_reg.size()[-1]
-        kernel_reg = kernel_reg.view(4 * self.anchor_num, 256, k, k)
-        kernel_cls = kernel_cls.view(2 * self.anchor_num, 256, k, k)
-
-        return kernel_reg, kernel_cls
-
-    def inference(self, x, kernel_reg, kernel_cls):
-        x = self.feature(x)
-        x_reg = self.conv_reg_x(x)
-        x_cls = self.conv_cls_x(x)
-
-        out_reg = self.adjust_reg(F.conv2d(x_reg, kernel_reg))
-        out_cls = F.conv2d(x_cls, kernel_cls)
-
-        return out_reg, out_cls'''
+
+class TrackerSiamFC(Tracker):
+
+    def __init__(self, net_path=None, **kwargs):
+
+        super(TrackerSiamFC, self).__init__('SiamFC', True)
+
+        # setup GPU device if available
+        self.cuda = torch.cuda.is_available()
+        self.device = torch.device('cuda:0' if self.cuda else 'cpu')
+
+        print('Training on device {}'.format(self.device))
+
+        '''setup GPU device if available'''
+        self.cuda = torch.cuda.is_available()
+        self.device = torch.device('cuda:0' if self.cuda else 'cpu')
+
+
+
+        # setup model
+        self.net = Net(
+            backbone=AlexNetV3(),
+            head=SiamFC(self.cfg.out_scale))
+
+        # load checkpoint if provided
+        if net_path is not None:
+            self.net.load_state_dict(torch.load(
+                net_path, map_location=lambda storage, loc: storage))
+        self.net = self.net.to(self.device)
+
+
+        # setup criterion
+        from network_siamfc import BalancedLoss
+        self.criterion = BalancedLoss()
+
+        # setup optimizer
+        self.optimizer = torch.optim.SGD(
+            self.net.parameters(),
+            lr=self.cfg.initial_lr,
+            weight_decay=self.cfg.weight_decay,
+            momentum=self.cfg.momentum)
+
+
+    def step(self, epoch, dataset, anchors, i = 0,  train=True):
+
+        # TODO: implement further
+
+
+        if train:
+            self.net.train()
+        else:
+            self.net.eval()
+
+        template, detection, regression_target, conf_target = dataset
+
+        if self.cuda:
+            template, detection = template.cuda(), detection.cuda()
+            regression_target, conf_target = regression_target.cuda(), conf_target.cuda()
+
+        pred_score, pred_regression = self.net(template, detection)
+
+        pred_conf = pred_score.reshape(-1, 2, config.size).permute(0, 2, 1)
+
+        pred_offset = pred_regression.reshape(-1, 4, config.size).permute(0, 2, 1)
+
+        cls_loss = self.criterion(pred_conf,conf_target)
+
+        reg_loss = rpn_smoothL1(pred_offset,
+                                regression_target,
+                                conf_target,
+                                config.num_pos,
+                                ohem=config.ohem_reg)
+
+        loss = cls_loss + config.lamb * reg_loss
+
+        if train:
+            self.optimizer.zero_grad()
+            loss.backward()
+            torch.nn.utils.clip_grad_norm_(self.net.parameters(), config.clip)
+            self.optimizer.step()
+
+        return cls_loss, reg_loss, loss
+
+
+
diff --git a/train/train_siamrpn.py b/train/train_siamrpn.py
index 42c0ffd..2934226 100644
--- a/train/train_siamrpn.py
+++ b/train/train_siamrpn.py
@@ -10,49 +10,76 @@ import numpy as np
 from tqdm import tqdm
 from torch.nn import init
 from config import config
-from net import TrackerSiamRPN
+from net import TrackerSiamRPN, TrackerSiamFC
+
 from data import TrainDataLoader
+from data_rgbt import TrainDataLoaderRGBT
 from torch.utils.data import DataLoader
+
 from util import util, AverageMeter, SavePlot
 from got10k.datasets import ImageNetVID, GOT10k
 from torchvision import datasets, transforms, utils
 from custom_transforms import Normalize, ToTensor, RandomStretch, \
     RandomCrop, CenterCrop, RandomBlur, ColorAug
+import wandb
+import shutil
+
+from train.experimentrgbt import RGBTSequence
+
 
 torch.manual_seed(1234) # config.seed
 
 
 parser = argparse.ArgumentParser(description='PyTorch SiameseRPN Training')
 
-parser.add_argument('--train_path', default='/home/arbi/desktop/GOT-10k', metavar='DIR',help='path to dataset')
-parser.add_argument('--experiment_name', default='default', metavar='DIR',help='path to weight')
+parser.add_argument('--train_path', default='/home/zuern/datasets/tracking/GOT10k', metavar='DIR',help='path to dataset')
+parser.add_argument('--experiment_name', default='SiamRPN', metavar='DIR',help='path to weight')
 parser.add_argument('--checkpoint_path', default=None, help='resume')
-# /home/arbi/desktop/GOT-10k # /Users/arbi/Desktop # /home/arbi/desktop/ILSVRC
-# 'experiments/default/model/model_e1.pth'
+
+
+
 def main():
 
+
+
     '''parameter initialization'''
     args = parser.parse_args()
     exp_name_dir = util.experiment_name_dir(args.experiment_name)
 
+
+    wandb.init(project="SiameseX", reinit=True)
+
+
+
     '''model on gpu'''
     model = TrackerSiamRPN()
+    # model = TrackerSiamFC()
 
     '''setup train data loader'''
-    name = 'GOT-10k'
-    assert name in ['VID', 'GOT-10k', 'All']
+
+    name = 'RGBT-234'
+
+
+    assert name in ['VID', 'GOT-10k', 'All', 'RGBT-234']
+
     if name == 'GOT-10k':
         root_dir = args.train_path
         seq_dataset = GOT10k(root_dir, subset='train')
     elif name == 'VID':
-        root_dir = '/home/arbi/desktop/ILSVRC'
+        root_dir = '/home/zuern/datasets/tracking/VID/ILSVRC'
         seq_dataset = ImageNetVID(root_dir, subset=('train'))
+
+    elif name == 'RGBT-234':
+        seq_dataset = RGBTSequence('/home/zuern/datasets/thermal_tracking/RGB-T234/', subset='train')
+
+
     elif name == 'All':
         root_dir_vid = '/home/arbi/desktop/ILSVRC'
         seq_datasetVID = ImageNetVID(root_dir_vid, subset=('train'))
         root_dir_got = args.train_path
         seq_datasetGOT = GOT10k(root_dir_got, subset='train')
         seq_dataset = util.data_split(seq_datasetVID, seq_datasetGOT)
+
     print('seq_dataset', len(seq_dataset))
 
     train_z_transforms = transforms.Compose([
@@ -62,7 +89,7 @@ def main():
         ToTensor()
     ])
 
-    train_data  = TrainDataLoader(seq_dataset, train_z_transforms, train_x_transforms, name)
+    train_data  = TrainDataLoaderRGBT(seq_dataset, train_z_transforms, train_x_transforms, name)
     anchors = train_data.anchors
     train_loader = DataLoader(  dataset    = train_data,
                                 batch_size = config.train_batch_size,
@@ -71,14 +98,22 @@ def main():
                                 pin_memory = True)
 
     '''setup val data loader'''
-    name = 'GOT-10k'
-    assert name in ['VID', 'GOT-10k', 'All']
+    name = 'RGBT-234'
+
+
+    assert name in ['VID', 'GOT-10k', 'All', 'RGBT-234']
     if name == 'GOT-10k':
         root_dir = args.train_path
         seq_dataset_val = GOT10k(root_dir, subset='val')
     elif name == 'VID':
         root_dir = '/home/arbi/desktop/ILSVRC'
         seq_dataset_val = ImageNetVID(root_dir, subset=('val'))
+
+
+    elif name == 'RGBT-234':
+        seq_dataset_val = RGBTSequence('/home/zuern/datasets/thermal_tracking/RGB-T234/', subset='eval')
+
+
     elif name == 'All':
         root_dir_vid = '/home/arbi/desktop/ILSVRC'
         seq_datasetVID = ImageNetVID(root_dir_vid, subset=('val'))
@@ -94,7 +129,7 @@ def main():
         ToTensor()
     ])
 
-    val_data  = TrainDataLoader(seq_dataset_val, valid_z_transforms, valid_x_transforms, name)
+    val_data  = TrainDataLoaderRGBT(seq_dataset_val, valid_z_transforms, valid_x_transforms, name)
     val_loader = DataLoader(    dataset    = val_data,
                                 batch_size = config.valid_batch_size,
                                 shuffle    = False,
@@ -103,7 +138,7 @@ def main():
 
     '''load weights'''
 
-    if not args.checkpoint_path == None:
+    if args.checkpoint_path:
         assert os.path.isfile(args.checkpoint_path), '{} is not valid checkpoint_path'.format(args.checkpoint_path)
         checkpoint = torch.load(args.checkpoint_path, map_location='cpu')
         if 'model' in checkpoint.keys():
@@ -128,13 +163,26 @@ def main():
 
     train_val_plot = SavePlot(exp_name_dir, 'train_val_plot')
 
+
+
+    from train.experimentrgbt import ExperimentRGBT
+    experiment = ExperimentRGBT('/home/zuern/datasets/thermal_tracking/RGB-T234/',
+                       experiment_name='RGBT-Train',
+                       subset='val')
+
+
+
+
     for epoch in range(config.epoches):
+
         model.net.train()
         if config.fix_former_3_layers:
                 util.freeze_layers(model.net)
         print('Train epoch {}/{}'.format(epoch+1, config.epoches))
         train_loss = []
+
         with tqdm(total=config.train_epoch_size) as progbar:
+
             for i, dataset in enumerate(train_loader):
 
                 closs, rloss, loss = model.step(epoch, dataset,anchors, i,  train=True)
@@ -155,12 +203,10 @@ def main():
                 progbar.update()
                 train_loss.append(train_tlosses.avg)
 
-                if i >= config.train_epoch_size - 1:
-
-                    '''save model'''
-                    model.save(model, exp_name_dir, epoch)
 
-                    break
+        print('saving model')
+        '''save model'''
+        model.save(model, exp_name_dir, epoch)
 
         train_loss = np.mean(train_loss)
 
@@ -192,10 +238,34 @@ def main():
                 if i >= config.val_epoch_size - 1:
                     break
 
+
+
         val_loss = np.mean(val_loss)
         train_val_plot.update(train_loss, val_loss)
         print ('Train loss: {}, val loss: {}'.format(train_loss, val_loss))
 
+        wandb.log({'Train loss': train_loss,
+                   'Val loss': val_loss},
+                    step = epoch + 1)
+
+
+        # Get curves of training
+
+        # remove sequences report dir and results dir:
+        if os.path.exists(experiment.result_dir):
+            shutil.rmtree(experiment.result_dir)
+        if os.path.exists(experiment.report_dir):
+            shutil.rmtree(experiment.report_dir)
+
+        experiment.run(model)
+        performance = experiment.report([model.name])
+
+        wandb.log({"Success_curve": wandb.Histogram(performance[model.name]['overall']['succ_curve']),
+                   "AO": performance[model.name]['overall']['ao'],
+                   "SR": performance[model.name]['overall']['sr'],
+                   "FPS": performance[model.name]['overall']['speed_fps']},
+                  step=epoch + 1)
+
 
 if __name__ == '__main__':
     main()
